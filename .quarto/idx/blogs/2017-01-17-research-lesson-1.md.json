{"title":"Research lessons learnt the hard way: #1 maintaining organised data files","markdown":{"yaml":{"layout":"post","title":"Research lessons learnt the hard way: #1 maintaining organised data files","date":"2017-01-17"},"headingText":"LESSON LEARNT #1: MAINTAINING ORGANISED DATA FILES","containsRefs":false,"markdown":"\nThis is the first post in a (hopefully not long) series of research lessons learned from making mistakes. Most of the lessons have been in various aspects of programming as none of my supervisors or fellow postgraduates have any interest in R or Python, so I have had to learn through books and online resources. Combined with the fact I do not have any history in computer science, I’ve learnt a lot through trial and error, and learning from the mistakes I have made. Keeping with the philosophy of this blog, my aim here is to share my experiences in research for the benefit of other people.\n\n\nThe first mistake I have made is not keeping an organised version of my data. One of my studies involved a response time task that was split into three blocks. The program that I used to create the experiment produced a separate data file for each block. The first step before I could analyse any data was to create a master version of the data that contained all three blocks. During this process, I copied and pasted all the responses into one spreadsheet and labelled it as the master file for each participant… or so I thought.\n\nRecently, I went to perform a different type of analysis on the data that required it to be changed from [long format to wide format](http://www.theanalysisfactor.com/wide-and-long-data/) before any data screening. However, it turns out I had only maintained an organised version of the master files for approximately half of the participants. This is either the result of not saving the master versions after I had analysed the trial data, or they are hidden in a separate folder that I cannot find. Either way, this is not good organisation and I clearly did not have future me in mind. I only have myself to blame, so what would be a better method of organisation to save time in future?\n\n## A BETTER ORGANISATION METHOD\n\nThe approach I have taken for most of the study is to maintain a folder that contains the participant’s data in several versions that can be used for different purposes:\n\n1. Raw data\nThis is the file that is produced directly from that whatever program you are using. For example, I used [PsychoPy](http://www.psychopy.org/) for my experiment which produces a .csv file (helpful if you use R). In my most recent study, I organised the task into three blocks which produced a separate .csv file for each. The first version of data in my participant folder are these three files. These are the raw files that are fresh from the participant. Nothing is done to them, and they are preserved as the original files.\n\n2. Readable data\nThe next step is to have a file that you can analyse straight away in the spreadsheet, or read into R. These are the master files that I mentioned above. As I had three separate files, I wanted all the trials to be included in one spreadsheet, ready to be analysed. Although this is still the raw data, it is something that you can analyse straight away with no messing around. Note: depending how you receive your data, you might find that this is the raw data that is fresh from the participant listed in step 1.\n\n3. Processed data\nThe next step is to perform any data screening requirements that are relevant to your study. For example, in my study only correct responses were retained, and then responses within certain boundaries (I previously wrote about how you can [write an R script](https://bartlettje.github.io/2016-11-22-tidy-response-data/) to automate this process). This produces a file that can be analysed for mean responses or whatever your dependent variable is. The important thing in this step is that you have a data file that is ready to go. If you need to come back to it for whatever reason, you can immediately rerun your analysis script.\n\n\nThis process leaves you with three (or two depending on the format that you receive the data) versions of the data that can be used immediately for different purposes. For example, for my main analysis, if I wanted to check I had recorded the mean values correctly, I could immediately go back to the file produced in step 3 and reanalyse it. However, if I had a different purpose like the motivation for this blog post, I would need the file produced in step 2. Organising your data to contain different versions with future you in mind saves you a lot of time and headaches. This issue could have been even more problematic if it was years instead of months down the line. I would have to spend even longer familiarising myself with the variable names and trying to remember what I was doing.\n\n## Take home message\nWhen you are analysing your data, have future you in mind. Keep an organised folder for each participant’s data in different versions that allows you to quickly go back and access it without having to process it again.\n","srcMarkdownNoYaml":"\nThis is the first post in a (hopefully not long) series of research lessons learned from making mistakes. Most of the lessons have been in various aspects of programming as none of my supervisors or fellow postgraduates have any interest in R or Python, so I have had to learn through books and online resources. Combined with the fact I do not have any history in computer science, I’ve learnt a lot through trial and error, and learning from the mistakes I have made. Keeping with the philosophy of this blog, my aim here is to share my experiences in research for the benefit of other people.\n\n## LESSON LEARNT #1: MAINTAINING ORGANISED DATA FILES\n\nThe first mistake I have made is not keeping an organised version of my data. One of my studies involved a response time task that was split into three blocks. The program that I used to create the experiment produced a separate data file for each block. The first step before I could analyse any data was to create a master version of the data that contained all three blocks. During this process, I copied and pasted all the responses into one spreadsheet and labelled it as the master file for each participant… or so I thought.\n\nRecently, I went to perform a different type of analysis on the data that required it to be changed from [long format to wide format](http://www.theanalysisfactor.com/wide-and-long-data/) before any data screening. However, it turns out I had only maintained an organised version of the master files for approximately half of the participants. This is either the result of not saving the master versions after I had analysed the trial data, or they are hidden in a separate folder that I cannot find. Either way, this is not good organisation and I clearly did not have future me in mind. I only have myself to blame, so what would be a better method of organisation to save time in future?\n\n## A BETTER ORGANISATION METHOD\n\nThe approach I have taken for most of the study is to maintain a folder that contains the participant’s data in several versions that can be used for different purposes:\n\n1. Raw data\nThis is the file that is produced directly from that whatever program you are using. For example, I used [PsychoPy](http://www.psychopy.org/) for my experiment which produces a .csv file (helpful if you use R). In my most recent study, I organised the task into three blocks which produced a separate .csv file for each. The first version of data in my participant folder are these three files. These are the raw files that are fresh from the participant. Nothing is done to them, and they are preserved as the original files.\n\n2. Readable data\nThe next step is to have a file that you can analyse straight away in the spreadsheet, or read into R. These are the master files that I mentioned above. As I had three separate files, I wanted all the trials to be included in one spreadsheet, ready to be analysed. Although this is still the raw data, it is something that you can analyse straight away with no messing around. Note: depending how you receive your data, you might find that this is the raw data that is fresh from the participant listed in step 1.\n\n3. Processed data\nThe next step is to perform any data screening requirements that are relevant to your study. For example, in my study only correct responses were retained, and then responses within certain boundaries (I previously wrote about how you can [write an R script](https://bartlettje.github.io/2016-11-22-tidy-response-data/) to automate this process). This produces a file that can be analysed for mean responses or whatever your dependent variable is. The important thing in this step is that you have a data file that is ready to go. If you need to come back to it for whatever reason, you can immediately rerun your analysis script.\n\n\nThis process leaves you with three (or two depending on the format that you receive the data) versions of the data that can be used immediately for different purposes. For example, for my main analysis, if I wanted to check I had recorded the mean values correctly, I could immediately go back to the file produced in step 3 and reanalyse it. However, if I had a different purpose like the motivation for this blog post, I would need the file produced in step 2. Organising your data to contain different versions with future you in mind saves you a lot of time and headaches. This issue could have been even more problematic if it was years instead of months down the line. I would have to spend even longer familiarising myself with the variable names and trying to remember what I was doing.\n\n## Take home message\nWhen you are analysing your data, have future you in mind. Keep an organised folder for each participant’s data in different versions that allows you to quickly go back and access it without having to process it again.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2017-01-17-research-lesson-1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"visual","theme":"solar","layout":"post","title":"Research lessons learnt the hard way: #1 maintaining organised data files","date":"2017-01-17"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}